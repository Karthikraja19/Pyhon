{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "9fc12bd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrix C:\n",
      "[[  2. -11.   3.]\n",
      " [  6.  -2.   3.]\n",
      " [  5.  18.  -4.]\n",
      " [  7.  25.   1.]]\n",
      "\n",
      "Matrix A1 = C^T * C:\n",
      "[[ 114.  231.   11.]\n",
      " [ 231. 1074.  -86.]\n",
      " [  11.  -86.   35.]]\n",
      "\n",
      "Characteristic equation of A1:\n",
      "1.0*x**3 - 1223.0*x**2 + 103138.0*x - 1007475.0\n",
      "\n",
      "Eigenvalues of A1:\n",
      "[1132.73283645   79.01012846   11.25703509]\n",
      "\n",
      "Eigenvectors of A1 (each column corresponds to an eigenvalue):\n",
      "[[-0.21977197 -0.84673264 -0.48450399]\n",
      " [-0.97274019  0.15252645  0.17467743]\n",
      " [ 0.07400541 -0.50968571  0.85717191]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import sympy as sp\n",
    "\n",
    "# Generate a random integer matrix C of size 4x3 \n",
    "#C = np.random.randint(1, 10, size=(4, 3))\n",
    "C = np.array([[2,-11,3], [6,-2,3], [5,18,-4], [7,25,1]], dtype=np.float64)\n",
    "print(\"Matrix C:\")\n",
    "print(C)\n",
    "\n",
    "# Compute A1 = C^T * C\n",
    "A1 = C.T @ C\n",
    "print(\"\\nMatrix A1 = C^T * C:\")\n",
    "print(A1)\n",
    "\n",
    "# Find the characteristic equation of A1\n",
    "A1_sym = sp.Matrix(A1)\n",
    "lambda_symbol = sp.symbols('x')\n",
    "char_eq = A1_sym.charpoly(lambda_symbol).as_expr()\n",
    "print(\"\\nCharacteristic equation of A1:\")\n",
    "print(char_eq)\n",
    "eigenvalues, eigenvectors = np.linalg.eig(A1)\n",
    "print(\"\\nEigenvalues of A1:\")\n",
    "print(eigenvalues)\n",
    "print(\"\\nEigenvectors of A1 (each column corresponds to an eigenvalue):\")\n",
    "print(eigenvectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "dc8ef9ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "First 10 iterates_1 of eigenvalue generated by the algorithm:\n",
      "[1123.1482989640858, 1132.686221720402, 1132.7326096837915, 1132.7328353418934, 1132.7328364397865, 1132.7328364451278]\n",
      "\n",
      "Final largest eigenvalue (λ1):\n",
      "1132.7328364451278\n",
      "\n",
      "Final corresponding eigenvector (x1), normalized (x̂1):\n",
      "[ 0.21977211  0.97274017 -0.07400533]\n",
      "\n",
      "Comparison with NumPy's computation:\n",
      "Largest eigenvalue (λ1) via NumPy: 1132.732836445155\n",
      "Normalized largest eigenvector (x̂1) via NumPy: [-0.21977197 -0.97274019  0.07400541]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def power_method(C, num_iterations=100, tol=1e-6):\n",
    "    n, _ = C.shape\n",
    "    # Start with a random vector\n",
    "    b_k = np.random.rand(n)\n",
    "    iterates = []\n",
    "    \n",
    "    for _ in range(num_iterations):\n",
    "        # Calculate the matrix-by-vector product Ab\n",
    "        b_k1 = np.dot(C, b_k)\n",
    "        \n",
    "        # Calculate the norm\n",
    "        b_k1_norm = np.linalg.norm(b_k1)\n",
    "        \n",
    "        # Re normalize the vector\n",
    "        b_k = b_k1 / b_k1_norm\n",
    "        \n",
    "        # Approximate the eigenvalue\n",
    "        lambda_k = np.dot(b_k.T, np.dot(C, b_k))\n",
    "        \n",
    "        iterates.append(lambda_k)\n",
    "        \n",
    "        # Check convergence\n",
    "        if len(iterates) > 1 and np.abs(iterates[-1] - iterates[-2]) < tol:\n",
    "            break\n",
    "    \n",
    "    return lambda_k, b_k, iterates\n",
    "\n",
    "# A2, A3 MATR\n",
    "lambda_1, x_1, iterates_1 = power_method(A1, 100)\n",
    "x_1_hat = x_1 / np.linalg.norm(x_1)\n",
    "\n",
    "x_1_hat_outer_product = np.outer(x_1_hat, x_1_hat)\n",
    "\n",
    "\n",
    "print(\"\\nFirst 10 iterates_1 of eigenvalue generated by the algorithm:\")\n",
    "print(iterates_1[:10])\n",
    "\n",
    "print(\"\\nFinal largest eigenvalue (λ1):\")\n",
    "print(lambda_1)\n",
    "\n",
    "print(\"\\nFinal corresponding eigenvector (x1), normalized (x̂1):\")\n",
    "print(x_1_hat)\n",
    "\n",
    "# Comparing results with numpy's linalg.eig function\n",
    "eigenvalues, eigenvectors = np.linalg.eig(A1)\n",
    "index_max = np.argmax(eigenvalues)\n",
    "largest_eigenvalue1 = eigenvalues[index_max]\n",
    "normalized_largest_eigenvector1 = eigenvectors[:, index_max] / np.linalg.norm(eigenvectors[:, index_max])\n",
    "\n",
    "print(\"\\nComparison with NumPy's computation:\")\n",
    "print(\"Largest eigenvalue (λ1) via NumPy:\", largest_eigenvalue1)\n",
    "print(\"Normalized largest eigenvector (x̂1) via NumPy:\", normalized_largest_eigenvector1)            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "8f9b3c69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrix A2:\n",
      " [[ 59.28926226 -11.15703684  29.42313898]\n",
      " [-11.15680009   2.18164073  -4.45680451]\n",
      " [ 29.42309073  -4.45693834  28.79626057]]\n",
      "\n",
      "First 10 iterates_2 of eigenvalue generated by the algorithm:\n",
      "[78.75797960005164, 79.00499127110662, 79.01002417442609, 79.01012634692341, 79.0101284209637, 79.0101284630654]\n",
      "\n",
      "Largest eigenvalue (λ2) of A2:\n",
      "79.0101284630654\n",
      "\n",
      "Corresponding eigenvector (x2), normalized (\\hat{x}_2):\n",
      "[ 0.84673084 -0.15252607  0.5096888 ]\n"
     ]
    }
   ],
   "source": [
    "x_1_hat_outer_product = np.outer(x_1_hat, x_1_hat)\n",
    "A2 = A1 - x_1_hat_outer_product @ A1\n",
    "\n",
    "print(\"Matrix A2:\\n\",A2)\n",
    "\n",
    "lambda_2, x_2, iterates_2 = power_method(A2, 100)\n",
    "x_2_hat = x_2 / np.linalg.norm(x_2)\n",
    "\n",
    "print(\"\\nFirst 10 iterates_2 of eigenvalue generated by the algorithm:\")\n",
    "print(iterates_2[:10])\n",
    "\n",
    "print(\"\\nLargest eigenvalue (λ2) of A2:\")\n",
    "print(lambda_2)\n",
    "print(\"\\nCorresponding eigenvector (x2), normalized (\\hat{x}_2):\")\n",
    "print(x_2_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "b9f2834f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrix A3:\n",
      " [[ 2.64267924 -0.9526339  -4.67504862]\n",
      " [-0.95274646  0.34346675  1.68548539]\n",
      " [-4.67526583  1.68559227  8.2708891 ]]\n",
      "\n",
      "First 10 iterates_2 of eigenvalue generated by the algorithm:\n",
      "[11.25703490747088, 11.25703509185307]\n",
      "\n",
      "Largest eigenvalue (λ3) of A3:\n",
      "11.25703509185307\n",
      "\n",
      "Corresponding eigenvector (x3), normalized (\\hat{x}_3):\n",
      "[ 0.48450703 -0.17467797 -0.85717008]\n"
     ]
    }
   ],
   "source": [
    "x_2_hat_outer_product = np.outer(x_2_hat, x_2_hat)\n",
    "A3 = A1 - x_1_hat_outer_product @ A1 - x_2_hat_outer_product @ A2\n",
    "\n",
    "print(\"Matrix A3:\\n\",A3)\n",
    "\n",
    "lambda_3, x_3, iterates_3 = power_method(A3, 100)\n",
    "x_3_hat = x_3 / np.linalg.norm(x_3)\n",
    "\n",
    "print(\"\\nFirst 10 iterates_2 of eigenvalue generated by the algorithm:\")\n",
    "print(iterates_3[:10])\n",
    "\n",
    "print(\"\\nLargest eigenvalue (λ3) of A3:\")\n",
    "print(lambda_3)\n",
    "print(\"\\nCorresponding eigenvector (x3), normalized (\\hat{x}_3):\")\n",
    "print(x_3_hat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e7e24c1",
   "metadata": {},
   "source": [
    "For λ1 and x_1_hat\n",
    "Largest eigenvalue (λ1) is significantly larger than the others.\n",
    "The corresponding eigenvector x_1_hat\n",
    "points in the direction of greatest variance.\n",
    "\n",
    "First 10 Iterates for λ2 and x_2_hat\n",
    "The iterates converge more slowly than for λ2 reflecting the reduced gap between the largest and the second-largest eigenvalues in A2\n",
    "The direction of x_2_hat is orthogonal to x_1_hat since A2 is constructed to remove the influence of x_1_hat\n",
    "\n",
    "First 10 Iterates for λ3 and x_3_hat\n",
    "Convergence is even slower, indicating the proximity of eigenvalues in A3\n",
    "The eigenvector x_3_hat orthogonal tox_1_hat and x_2_hat aligning with the expectation due to the construction of A3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "1e0f1601",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stationary point found at: [1.00005111 1.00010296]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def f(x, y):\n",
    "    return 10*x**4 - 20*x**2*y + x**2 + 10*y**2 - 2*x + 1\n",
    "\n",
    "def grad_f(x, y):\n",
    "    df_dx = 40*x**3 - 40*x*y + 2*x - 2\n",
    "    df_dy = -20*x**2 + 20*y\n",
    "    return np.array([df_dx, df_dy])\n",
    "\n",
    "def armijo_rule(x, grad, alpha=1, beta=0.5, sigma=0.1):\n",
    "    while f(x[0] - alpha * grad[0], x[1] - alpha * grad[1]) > f(x[0], x[1]) - sigma * alpha * np.dot(grad, grad):\n",
    "        alpha *= beta\n",
    "    return alpha\n",
    "\n",
    "def gradient_descent_with_armijo(init_point, max_iter=1000, epsilon=1e-6):\n",
    "    x = np.array(init_point)\n",
    "    for i in range(max_iter):\n",
    "        grad = grad_f(x[0], x[1])\n",
    "        if np.linalg.norm(grad) < epsilon:\n",
    "            break\n",
    "        alpha = armijo_rule(x, grad)\n",
    "        x = x - alpha * grad\n",
    "    return x\n",
    "\n",
    "# Initial point\n",
    "init_point = [0.1, 0.1]  # Example initial point\n",
    "\n",
    "stationary_point = gradient_descent_with_armijo(init_point)\n",
    "print(f\"Stationary point found at: {stationary_point}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "92d82557",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class ObjectiveFunction():\n",
    "\n",
    "    def eval(self, x, y):\n",
    "        return 10 * (x ** 4) - 20 * (x ** 2) * y + (x ** 2) + 10 * (y ** 2) - 2 * x  + 1\n",
    "\n",
    "    def gradient(self, x, y):\n",
    "        return np.array([40 * (x ** 3) - 40 * x * y + 2 * x -2 , 20 * y - 20 * (x ** 2)])\n",
    "\n",
    "    def hessian(self, x, y):\n",
    "        df_dx2 = 120 * (x ** 2) - 40 * y + 2\n",
    "        df_dxy= -40 * x\n",
    "        df_dy2 = 20\n",
    "\n",
    "        return np.array([[df_dx2, df_dxy], [df_dxy, df_dy2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "e447fe40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal Point: (1.0000860864244827, 1.0001742864714784)\n",
      "Iterations: 641\n"
     ]
    }
   ],
   "source": [
    "class GradientMethod():\n",
    "    def __init__(self):\n",
    "        self.iterations = 0\n",
    "\n",
    "    def optimize(self, x_0, y_0, func, beta, sigma, epsilon):\n",
    "        x = x_0\n",
    "        y = y_0\n",
    "        while self.stopping_criteria(x,y, func, epsilon):\n",
    "            descent_direction = -1 * func.gradient(x,y)\n",
    "\n",
    "            step_size = self.step_size(x,y,func,beta,descent_direction,sigma)\n",
    "\n",
    "            # update step\n",
    "            x = x + step_size * descent_direction[0]\n",
    "            y = y + step_size * descent_direction[1]\n",
    "            self.iterations += 1\n",
    "\n",
    "        return x , y\n",
    "\n",
    "    def stopping_criteria(self, x,y, func, epsilon):\n",
    "        return np.linalg.norm(func.gradient(x,y)) >= epsilon\n",
    "\n",
    "    def step_size(self, x,y, func, beta, d, sigma):\n",
    "        i = 0\n",
    "        inequality_satisfied = True\n",
    "        while inequality_satisfied:\n",
    "            if func.eval(x + np.power(beta, i) * d[0], y + np.power(beta, i) * d[1]) <= func.eval(x,y) + np.power(beta, i) * sigma * func.gradient(x,y).dot(d):\n",
    "                break\n",
    "            i += 1\n",
    "\n",
    "        return np.power(beta, i)\n",
    "    \n",
    "objective = ObjectiveFunction()\n",
    "starting_point = np.array([-1.2, 1])\n",
    "x0 = -1.2\n",
    "y0 = 1\n",
    "beta = 0.5\n",
    "sigma = 0.0001\n",
    "epsilon = 0.0001\n",
    "\n",
    "optimizer = GradientMethod()\n",
    "\n",
    "x = optimizer.optimize(x0,y0, objective,beta,sigma,epsilon)\n",
    "\n",
    "print(f'Optimal Point: {x}')\n",
    "print(f'Iterations: {optimizer.iterations}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "024a33b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterate 1: x = 0.5938, y = 0.4219, α = 0.0156, f(x, y) = 0.2131\n",
      "Iterate 2: x = 0.6322, y = 0.4002, α = 0.0156, f(x, y) = 0.1353\n",
      "Iterate 3: x = 0.6556, y = 0.3999, α = 0.0312, f(x, y) = 0.1276\n",
      "Iterate 4: x = 0.6526, y = 0.4186, α = 0.0312, f(x, y) = 0.1212\n",
      "Iterate 5: x = 0.6684, y = 0.4231, α = 0.0312, f(x, y) = 0.1155\n",
      "Iterate 6: x = 0.6704, y = 0.4526, α = 0.0625, f(x, y) = 0.1087\n",
      "Iterate 7: x = 0.6820, y = 0.4516, α = 0.0156, f(x, y) = 0.1029\n",
      "Iterate 8: x = 0.7486, y = 0.5194, α = 0.2500, f(x, y) = 0.0800\n",
      "Iterate 9: x = 0.7373, y = 0.5322, α = 0.0156, f(x, y) = 0.0703\n",
      "Iterate 10: x = 0.8325, y = 0.6458, α = 0.5000, f(x, y) = 0.0504\n",
      "\n",
      "Optimal points: x* = 0.952887534774993, y* = 0.9066781285019561, f(x*, y*) = 0.002236916771591435\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def f(x, y):\n",
    "    return 10*x**4 - 20*x**2*y + x**2 + 10*y**2 - 2*x + 1\n",
    "\n",
    "def grad_f(x, y):\n",
    "    return np.array([40*x**3 - 40*x*y + 2*x - 2, -20*x**2 + 20*y])\n",
    "\n",
    "def armijo_rule(x, y, alpha, grad, beta=0.5, sigma=0.4):\n",
    "    \"\"\"Adjust step size using Armijo's rule.\"\"\"\n",
    "    while f(x - alpha * grad[0], y - alpha * grad[1]) > f(x, y) - sigma * alpha * np.dot(grad, grad):\n",
    "        alpha *= beta\n",
    "    return alpha\n",
    "\n",
    "# Gradient Descent with Armijo's Rule\n",
    "def gradient_descent_armijo(x0, y0, max_iters=100, tol=1e-6):\n",
    "    x, y = x0, y0\n",
    "    for i in range(max_iters):\n",
    "        grad = grad_f(x, y)\n",
    "        if np.linalg.norm(grad) < tol:\n",
    "            break\n",
    "        alpha = 1  # Initial step size\n",
    "        alpha = armijo_rule(x, y, alpha, grad)\n",
    "        x_new = x - alpha * grad[0]\n",
    "        y_new = y - alpha * grad[1]\n",
    "        \n",
    "        if i < 10:  # Print the first 10 iterates\n",
    "            print(f\"Iterate {i+1}: x = {x_new:.4f}, y = {y_new:.4f}, α = {alpha:.4f}, f(x, y) = {f(x_new, y_new):.4f}\")\n",
    "        \n",
    "        x, y = x_new, y_new\n",
    "\n",
    "    return x, y, f(x, y)\n",
    "\n",
    "# Initial guess\n",
    "x0, y0 = 0.5, 0.5\n",
    "\n",
    "# Run the gradient descent\n",
    "x_star, y_star, f_star = gradient_descent_armijo(x0, y0)\n",
    "\n",
    "print(f\"\\nOptimal points: x* = {x_star}, y* = {y_star}, f(x*, y*) = {f_star}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
